{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveframe v4.0 \u2014 Plug\u2011and\u2011Play Quickstart (Colab & local)\n",
    "\n",
    "Run **Runtime \u2192 Run all**. This notebook will:\n",
    "1) Install minimal dependencies\n",
    "2) Clone the repo (if not already present in Colab)\n",
    "3) Auto-discover CSVs in `Analysis/` and `Demos/Data/` (recursive)\n",
    "4) Fall back to an upload dialog if none are found\n",
    "5) Plot common observables when columns exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_and_import"
   },
   "outputs": [],
   "source": [
    "# 1) Install + import deps (safe to run multiple times)\n",
    "!pip -q install numpy pandas matplotlib\n",
    "import sys, platform, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print('Python:', sys.version)\n",
    "print('Platform:', platform.platform())\n",
    "print('pandas:', pd.__version__)\n",
    "print('numpy:', np.__version__)\n",
    "print('matplotlib:', plt.matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# 2) Ensure the repo is available (Colab)\n",
    "REPO_URL = 'https://github.com/Wright-Shawn/Waveframe-v4.0.git'\n",
    "REPO_DIR = '/content/Waveframe-v4.0'\n",
    "if os.path.isdir('/content') and not os.path.isdir(REPO_DIR):\n",
    "    print('Cloning repo into Colab workspace...')\n",
    "    !git clone $REPO_URL\n",
    "else:\n",
    "    print('Repo already present or running locally.')\n",
    "\n",
    "# Switch working dir if in Colab\n",
    "if os.path.isdir(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "print('CWD:', os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "discover_csvs"
   },
   "outputs": [],
   "source": [
    "# 3) Discover CSVs\n",
    "CANDIDATE_DIRS = ['Analysis', 'analysis', 'Demos/Data']\n",
    "csvs = []\n",
    "for rel in CANDIDATE_DIRS:\n",
    "    root = os.path.abspath(rel)\n",
    "    found = sorted(glob.glob(os.path.join(root, '**', '*.csv'), recursive=True))\n",
    "    if found:\n",
    "        print(f'Found {len(found)} CSV(s) under {rel}')\n",
    "        csvs.extend(found)\n",
    "\n",
    "print('\\nAll discovered CSVs:')\n",
    "for i, p in enumerate(csvs):\n",
    "    print(f'  [{i}] {p}')\n",
    "\n",
    "if not csvs:\n",
    "    print('\\nNo CSVs found. Use the upload dialog below to add one.')\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()  # opens file picker UI\n",
    "        os.makedirs('Uploaded', exist_ok=True)\n",
    "        for name, data in uploaded.items():\n",
    "            with open(os.path.join('Uploaded', name), 'wb') as f:\n",
    "                f.write(data)\n",
    "            csvs.append(os.path.abspath(os.path.join('Uploaded', name)))\n",
    "        print('Uploaded CSVs registered:')\n",
    "        for i, p in enumerate(csvs):\n",
    "            print(f'  [{i}] {p}')\n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError('No CSVs found and upload is unavailable in this environment.')\n",
    "\n",
    "# Choose which CSV to load\n",
    "CSV_INDEX = 0  # change if you have multiple CSVs and want a different one\n",
    "csv_path = csvs[CSV_INDEX]\n",
    "print('\\nUsing CSV ->', csv_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Columns:', list(df.columns))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plotting"
   },
   "outputs": [],
   "source": [
    "# 4) Detect columns and plot\n",
    "def pick(first_match_from, columns):\n",
    "    for name in first_match_from:\n",
    "        if name in columns:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "Z = pick(['z','redshift','Z'], df.columns)\n",
    "E = pick(['E','E_z','E(z)'], df.columns)\n",
    "DA = pick(['D_A','D_A(z)','DA','DA_z','angular_diameter_distance'], df.columns)\n",
    "H = pick(['H','H_z','H(z)','Hz'], df.columns)\n",
    "G = pick(['growth','f_sigma8','f\u03c38','f_s8','fs8'], df.columns)\n",
    "\n",
    "print('Detected ->', {'z':Z, 'E':E, 'D_A':DA, 'H':H, 'growth':G})\n",
    "\n",
    "def maybe_plot(xname, yname, title):\n",
    "    if xname and yname:\n",
    "        plt.figure()\n",
    "        plt.plot(df[xname], df[yname])\n",
    "        plt.xlabel(xname); plt.ylabel(yname); plt.title(title)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        return True\n",
    "    else:\n",
    "        print(f'Skipping {title}: missing columns')\n",
    "        return False\n",
    "\n",
    "maybe_plot(Z, E, 'E(z)')\n",
    "maybe_plot(Z, DA, 'D_A(z)')\n",
    "maybe_plot(Z, H, 'H(z)')\n",
    "maybe_plot(Z, G, 'Growth (proxy)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Save figures\n",
    "Uncomment and run the cell below to save all open figures into `Figures/auto/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_figs"
   },
   "outputs": [],
   "source": [
    "# SAVE = False\n",
    "# if SAVE:\n",
    "#     out_dir = os.path.abspath(os.path.join('Figures', 'auto'))\n",
    "#     os.makedirs(out_dir, exist_ok=True)\n",
    "#     for i, num in enumerate(plt.get_fignums(), start=1):\n",
    "#         fig = plt.figure(num)\n",
    "#         fig.savefig(os.path.join(out_dir, f'plot_{i:02d}.png'), dpi=150, bbox_inches='tight')\n",
    "#     print('Saved to:', out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}